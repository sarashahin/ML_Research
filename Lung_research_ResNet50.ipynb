{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "name": "Lung_research_ResNet50",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7699872,
          "sourceType": "datasetVersion",
          "datasetId": 4494542
        }
      ],
      "dockerImageVersionId": 30648,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarashahin/ML_Research/blob/main/Lung_research_ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'lung-resnet:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4494542%2F7699872%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240322%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240322T151008Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Daa65685ca2f2da00e751c49fc2bb819fea7938d81822b86599d769315be28860f808319b4df8ec8561a825c8b6ab2452b83b8fc30df1be68bce88abce6f3b80e641dd0b9b4dd860b5ea4b806f54dd620171614efbc91f231202e3bcb22ef5cfcdc3d4a91eda6011403884033e54a0ee2b1ed2b56fde4ef5012434702b6a32daad483abad62d3e239c08988661a6060e88aea22c58a29dd8038365a92cf4fcc4d7419d891eeb740c505ba1dd051784d739714bba9c167a72d6664391b9d4c505d411cb4d02ba1f192e68f649ce9dc87053e2f1872aa5b266c8ec43a9b365cb568997734ebf66df8f9da3a4cdd82f5e77095684d11ae5a429d07e56e68c7ea6bc3'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "kxMN_NLjtlqp"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cWjtiNYqtmYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_BLa6x2Tf44C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  import important Libraries\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import GaussianNoise\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "rl_9h_Slf3_j",
        "execution": {
          "iopub.status.busy": "2024-02-26T21:09:13.558301Z",
          "iopub.execute_input": "2024-02-26T21:09:13.558678Z",
          "iopub.status.idle": "2024-02-26T21:09:13.567649Z",
          "shell.execute_reply.started": "2024-02-26T21:09:13.558646Z",
          "shell.execute_reply": "2024-02-26T21:09:13.566723Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for GPU availability\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "tf.config.experimental.list_physical_devices('GPU')"
      ],
      "metadata": {
        "id": "yVHQXUCSNFzl",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:17:54.518992Z",
          "iopub.execute_input": "2024-02-26T20:17:54.519513Z",
          "iopub.status.idle": "2024-02-26T20:17:54.709819Z",
          "shell.execute_reply.started": "2024-02-26T20:17:54.519475Z",
          "shell.execute_reply": "2024-02-26T20:17:54.708724Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "rMh6IjY4yCT-",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:17:54.710938Z",
          "iopub.execute_input": "2024-02-26T20:17:54.711303Z",
          "iopub.status.idle": "2024-02-26T20:17:54.745338Z",
          "shell.execute_reply.started": "2024-02-26T20:17:54.71127Z",
          "shell.execute_reply": "2024-02-26T20:17:54.74437Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load pretrained ResNet50 model without the top layer\n",
        "# using weights that have been trained on the ImageNet dataset\n",
        "base_model = ResNet50(weights='imagenet', include_top=False)\n"
      ],
      "metadata": {
        "id": "fH9mVNFaf4C5",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:17:54.746538Z",
          "iopub.execute_input": "2024-02-26T20:17:54.746876Z",
          "iopub.status.idle": "2024-02-26T20:17:58.020507Z",
          "shell.execute_reply.started": "2024-02-26T20:17:54.746849Z",
          "shell.execute_reply": "2024-02-26T20:17:58.01932Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze/Unfreeze the layers of the base model\n",
        "# for layer in base_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# for layer in base_model.layers[-2:]:\n",
        "#     layer.trainable = True\n",
        "\n",
        "# freeze the initial layers\n",
        "for layer in base_model.layers[:4]:\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "id": "vAOLeM_1f4GB",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:17:58.023607Z",
          "iopub.execute_input": "2024-02-26T20:17:58.024096Z",
          "iopub.status.idle": "2024-02-26T20:17:58.029609Z",
          "shell.execute_reply.started": "2024-02-26T20:17:58.02406Z",
          "shell.execute_reply": "2024-02-26T20:17:58.028603Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "09tKjTc-f4Jb",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:17:58.030868Z",
          "iopub.execute_input": "2024-02-26T20:17:58.031142Z",
          "iopub.status.idle": "2024-02-26T20:17:58.04194Z",
          "shell.execute_reply.started": "2024-02-26T20:17:58.031119Z",
          "shell.execute_reply": "2024-02-26T20:17:58.041194Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vetEicSmXeE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with the path\n",
        "dataset_path_train = '/kaggle/input/lung-resnet/train 2'\n",
        "dataset_path_test = '/kaggle/input/lung-resnet/test 2'\n",
        "train_path = os.path.join(dataset_path_train, 'train')\n",
        "test_path = os.path.join(dataset_path_test, 'test')\n",
        "\n"
      ],
      "metadata": {
        "id": "LLDVtMh4f4MA",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:17:58.043134Z",
          "iopub.execute_input": "2024-02-26T20:17:58.043881Z",
          "iopub.status.idle": "2024-02-26T20:17:58.053185Z",
          "shell.execute_reply.started": "2024-02-26T20:17:58.043856Z",
          "shell.execute_reply": "2024-02-26T20:17:58.052397Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_random_images(class_names, train_path, num_images=5):\n",
        "    fig, axes = plt.subplots(len(class_names), num_images, figsize=(20, 15))\n",
        "    for row, cls in enumerate(class_names):\n",
        "        path = os.path.join(train_path, cls)\n",
        "        images = os.listdir(path)\n",
        "        selected_images = random.sample(images, num_images)\n",
        "        print(f\"Class: {cls}\")\n",
        "        for col, img in enumerate(selected_images):\n",
        "            img_path = os.path.join(path, img)\n",
        "            image = load_img(img_path, target_size=(240, 240))\n",
        "            if len(class_names) == 1:\n",
        "                ax = axes[col]\n",
        "            else:\n",
        "                ax = axes[row, col]\n",
        "            ax.imshow(image)\n",
        "            ax.set_title(cls)\n",
        "            ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "class_names = ['BENIGN', 'MALIGNANT', 'NORMAL']\n",
        "display_random_images(class_names, train_path)"
      ],
      "metadata": {
        "id": "Xfic2OGrRitl",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:17:58.054139Z",
          "iopub.execute_input": "2024-02-26T20:17:58.054416Z",
          "iopub.status.idle": "2024-02-26T20:18:00.875062Z",
          "shell.execute_reply.started": "2024-02-26T20:17:58.054394Z",
          "shell.execute_reply": "2024-02-26T20:18:00.873641Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  imbalance classes train set\n",
        "\n",
        "def plot_class_distribution(train_path, class_names):\n",
        "    class_counts = {}\n",
        "    for cls in class_names:\n",
        "        path = os.path.join(train_path, cls)\n",
        "        count = len(os.listdir(path))\n",
        "        class_counts[cls] = count\n",
        "\n",
        "    sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()))\n",
        "    plt.title(\"Class Distribution\")\n",
        "    plt.xlabel(\"Classes\")\n",
        "    plt.ylabel(\"Number of images\")\n",
        "    plt.show()\n",
        "\n",
        "plot_class_distribution(train_path, class_names)\n"
      ],
      "metadata": {
        "id": "r4cTxBgASKJ-",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:00.877063Z",
          "iopub.execute_input": "2024-02-26T20:18:00.877413Z",
          "iopub.status.idle": "2024-02-26T20:18:01.054656Z",
          "shell.execute_reply.started": "2024-02-26T20:18:00.877386Z",
          "shell.execute_reply": "2024-02-26T20:18:01.053697Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_class_distribution(test_path_path, class_names):\n",
        "    class_counts = {}\n",
        "    for cls in class_names:\n",
        "        path = os.path.join(test_path, cls)\n",
        "        count = len(os.listdir(path))\n",
        "        class_counts[cls] = count\n",
        "\n",
        "    sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()))\n",
        "    plt.title(\"Class Distribution\")\n",
        "    plt.xlabel(\"Classes\")\n",
        "    plt.ylabel(\"Number of images\")\n",
        "    plt.show()\n",
        "\n",
        "plot_class_distribution(test_path, class_names)"
      ],
      "metadata": {
        "id": "Aa0FAbNuTK5f",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:01.055871Z",
          "iopub.execute_input": "2024-02-26T20:18:01.056169Z",
          "iopub.status.idle": "2024-02-26T20:18:01.376084Z",
          "shell.execute_reply.started": "2024-02-26T20:18:01.056144Z",
          "shell.execute_reply": "2024-02-26T20:18:01.3752Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SNR (dB) = 10 × log ⁡ 10 ( signal power/ noise power )\n",
        "\n",
        "# power of the signal (image pixel values)\n",
        "\n",
        "# noise power(variance of the noise)\n",
        "\n",
        "\n",
        "\n",
        "def calculate_snr(image, snr_db):\n",
        "    # calculate signal power\n",
        "    signal_power = np.mean(image ** 2)\n",
        "\n",
        "    # calculate noise power\n",
        "    noise_power = signal_power / (10 ** (snr_db / 10)) #Convert SNR from dB to linear scale and calculate noise power\n",
        "    return noise_power\n"
      ],
      "metadata": {
        "id": "bE4byoOHfov_",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:01.377319Z",
          "iopub.execute_input": "2024-02-26T20:18:01.377679Z",
          "iopub.status.idle": "2024-02-26T20:18:01.383582Z",
          "shell.execute_reply.started": "2024-02-26T20:18:01.377649Z",
          "shell.execute_reply": "2024-02-26T20:18:01.38268Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_gaussian_noise(image, snr_db):\n",
        "    row, col, ch = image.shape\n",
        "    mean = 0\n",
        "    noise_power = calculate_snr(image, snr_db)\n",
        "    sigma = np.sqrt(noise_power)\n",
        "    gauss = np.random.normal(mean, sigma, (row, col, ch))\n",
        "    noisy = image + gauss\n",
        "    return np.clip(noisy, 0, 255)\n",
        "\n",
        "\n",
        "def add_salt_pepper_noise(image, snr_db):\n",
        "    row, col, ch = image.shape\n",
        "    s_vs_p = 0.5\n",
        "    snr_linear = 10 ** (snr_db / 10) #converting it to a linear scale makes it easier in calculations\n",
        "    corruption_ratio = 0.20 / (1 + snr_linear) #mapping the SNR to the amount of salt and pepper noise to add to the image\n",
        "    # using a logarithmic scale for non-linear mapping\n",
        "    # corruption_ratio = np.log10(1 + snr_linear**2) / np.log10(1 + max(snr_range)**2)  # max(snr_range) for normalization\n",
        "    amount = corruption_ratio * image.size\n",
        "    num_salt = np.ceil(amount * s_vs_p).astype(int)\n",
        "    num_pepper = np.ceil(amount * (1 - s_vs_p)).astype(int)\n",
        "    coords = [np.random.randint(0, i - 1, num_salt) for i in image.shape]\n",
        "    image[coords] = 1\n",
        "    coords = [np.random.randint(0, i - 1, num_pepper) for i in image.shape]\n",
        "    image[coords] = 0\n",
        "    return image\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SwAOzkw2fozV",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:01.384853Z",
          "iopub.execute_input": "2024-02-26T20:18:01.385257Z",
          "iopub.status.idle": "2024-02-26T20:18:01.394912Z",
          "shell.execute_reply.started": "2024-02-26T20:18:01.385226Z",
          "shell.execute_reply": "2024-02-26T20:18:01.39414Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define SNR range between 30 - 40db\n",
        "snr_range = np.linspace(28, 40, num=5)\n",
        "\n",
        "# global variables to log noise details\n",
        "global_noise_log = []\n",
        "\n",
        "def custom_preprocessing_function(image):\n",
        "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
        "    snr_db = random.choice(snr_range)\n",
        "    noise_type = random.choice(['gaussian', 'salt_pepper'])\n",
        "\n",
        "    # add noise to the image\n",
        "    if noise_type == 'gaussian':\n",
        "        image = add_gaussian_noise(image, snr_db)\n",
        "    else:\n",
        "        image = add_salt_pepper_noise(image, snr_db)\n",
        "\n",
        "    # log noise details\n",
        "    global_noise_log.append({'noise_type': noise_type, 'snr': snr_db})\n",
        "\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "68fSOhqg_5fO",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:01.39586Z",
          "iopub.execute_input": "2024-02-26T20:18:01.396121Z",
          "iopub.status.idle": "2024-02-26T20:18:01.409006Z",
          "shell.execute_reply.started": "2024-02-26T20:18:01.396099Z",
          "shell.execute_reply": "2024-02-26T20:18:01.408191Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to display images\n",
        "def plotImages(images_arr, n_images=5):\n",
        "    fig, axes = plt.subplots(1, n_images, figsize=(30, 35))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(images_arr, axes):\n",
        "        ax.imshow(img.astype('uint8'))\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hD0relPngbTj",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:01.413344Z",
          "iopub.execute_input": "2024-02-26T20:18:01.413685Z",
          "iopub.status.idle": "2024-02-26T20:18:01.419776Z",
          "shell.execute_reply.started": "2024-02-26T20:18:01.413662Z",
          "shell.execute_reply": "2024-02-26T20:18:01.418957Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using K-Fold cross-validation, the data is split into training and validation sets multiple times. For each split, data generators are created to feed both noisy and clean images into the model for training and evaluation."
      ],
      "metadata": {
        "id": "9tl0obwCeW_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get all image paths and their labels\n",
        "def get_images_and_labels(base_dir):\n",
        "    classes = ['BENIGN', 'MALIGNANT', 'NORMAL']\n",
        "    images = []\n",
        "    labels = []\n",
        "    for cls in classes:\n",
        "        cls_folder = os.path.join(base_dir, cls)\n",
        "        cls_images = [os.path.join(cls_folder, filename) for filename in os.listdir(cls_folder)]\n",
        "        images += cls_images\n",
        "        labels += [cls] * len(cls_images)\n",
        "    return images, labels\n",
        "\n",
        "train_images, train_labels = get_images_and_labels(train_path)"
      ],
      "metadata": {
        "id": "8scgPzw2n5ET",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:01.42088Z",
          "iopub.execute_input": "2024-02-26T20:18:01.421159Z",
          "iopub.status.idle": "2024-02-26T20:18:01.436831Z",
          "shell.execute_reply.started": "2024-02-26T20:18:01.421137Z",
          "shell.execute_reply": "2024-02-26T20:18:01.436076Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a DataFrame with the file paths and labels\n",
        "df = pd.DataFrame({'filename': train_images, 'class': train_labels})"
      ],
      "metadata": {
        "id": "blXIAttCsUXb",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:01.437879Z",
          "iopub.execute_input": "2024-02-26T20:18:01.438107Z",
          "iopub.status.idle": "2024-02-26T20:18:01.44338Z",
          "shell.execute_reply.started": "2024-02-26T20:18:01.438088Z",
          "shell.execute_reply": "2024-02-26T20:18:01.442508Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define ImageDataGenerators\n",
        "# is used for data augmentation and preprocessing of training a machine learning model with noisy images\n",
        "train_datagen_noise = ImageDataGenerator(preprocessing_function=\n",
        "        custom_preprocessing_function,\n",
        "        rotation_range=10,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        # vertical_flip=True,\n",
        "        shear_range=0.1,  #\n",
        "        zoom_range=0.1,\n",
        "        brightness_range=[0.8,1.2])\n"
      ],
      "metadata": {
        "id": "sYphK8fan5K6",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:01.444665Z",
          "iopub.execute_input": "2024-02-26T20:18:01.445047Z",
          "iopub.status.idle": "2024-02-26T20:18:01.453426Z",
          "shell.execute_reply.started": "2024-02-26T20:18:01.445017Z",
          "shell.execute_reply": "2024-02-26T20:18:01.452616Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen_clean = ImageDataGenerator(preprocessing_function=\n",
        "        preprocess_input,\n",
        "        rotation_range=10,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        # vertical_flip=True,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        brightness_range=[0.8,1.2])"
      ],
      "metadata": {
        "id": "mrJ82uoCtCPi",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:01.454471Z",
          "iopub.execute_input": "2024-02-26T20:18:01.454743Z",
          "iopub.status.idle": "2024-02-26T20:18:01.463847Z",
          "shell.execute_reply.started": "2024-02-26T20:18:01.454722Z",
          "shell.execute_reply": "2024-02-26T20:18:01.462996Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_datagen_clean = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "val_datagen_noise = ImageDataGenerator(preprocessing_function=custom_preprocessing_function)"
      ],
      "metadata": {
        "id": "8o0ccLvMtFwQ",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:01.464885Z",
          "iopub.execute_input": "2024-02-26T20:18:01.465502Z",
          "iopub.status.idle": "2024-02-26T20:18:01.47376Z",
          "shell.execute_reply.started": "2024-02-26T20:18:01.465466Z",
          "shell.execute_reply": "2024-02-26T20:18:01.472796Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform K-Fold Cross-Validation\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "qxDo5F9Zn5OY",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:01.474684Z",
          "iopub.execute_input": "2024-02-26T20:18:01.474958Z",
          "iopub.status.idle": "2024-02-26T20:18:01.483133Z",
          "shell.execute_reply.started": "2024-02-26T20:18:01.474929Z",
          "shell.execute_reply": "2024-02-26T20:18:01.482391Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop iterates over each fold//  get the indices of the training and validation sets\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
        "    print(f\"Running fold {fold + 1}\")\n",
        "    train_df = df.iloc[train_idx]\n",
        "    val_df = df.iloc[val_idx]\n",
        "\n",
        "    # Create the generators using flow_from_dataframe\n",
        "    train_generator_noise = train_datagen_noise.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        directory=None,\n",
        "        x_col='filename',\n",
        "        y_col='class',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    train_generator_clean = train_datagen_clean.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        directory=None,\n",
        "        x_col='filename',\n",
        "        y_col='class',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    val_generator_clean = val_datagen_clean.flow_from_dataframe(\n",
        "        dataframe=val_df,\n",
        "        directory=None,\n",
        "        x_col='filename',\n",
        "        y_col='class',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    val_generator_noise = val_datagen_noise.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=None,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        "    )"
      ],
      "metadata": {
        "id": "11q2lF26KBgo",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:01.484119Z",
          "iopub.execute_input": "2024-02-26T20:18:01.484397Z",
          "iopub.status.idle": "2024-02-26T20:18:02.554289Z",
          "shell.execute_reply.started": "2024-02-26T20:18:01.484375Z",
          "shell.execute_reply": "2024-02-26T20:18:02.553487Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # retrieve and display images from the noisy data generator\n",
        "    print(\"train_generator_noise:\")\n",
        "    images, labels = next(train_generator_noise)\n",
        "    plotImages(images[:5])\n",
        "\n",
        "    print(\"train_generator_clean:\")\n",
        "    # retrieve and display images from the clean data generator\n",
        "    images, labels = next(train_generator_clean)\n",
        "    plotImages(images[:5])"
      ],
      "metadata": {
        "id": "zX3MM8MPyOl1",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:02.555705Z",
          "iopub.execute_input": "2024-02-26T20:18:02.556104Z",
          "iopub.status.idle": "2024-02-26T20:18:05.8615Z",
          "shell.execute_reply.started": "2024-02-26T20:18:02.55607Z",
          "shell.execute_reply": "2024-02-26T20:18:05.860506Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_QommYC58xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # add custom layers on top of the base model\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Dense(1024, activation='relu', kernel_regularizer=l2(0.4))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(512, activation='relu', kernel_regularizer=l2(0.4))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    # x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "    # x = Dropout(0.5)(x)  # Additional dropout layer\n",
        "    # add a GaussianNoise layer to simulate and denoise from noise during training\n",
        "    # x = GaussianNoise(0.1)(x)\n",
        "    predictions = Dense(3, activation='softmax')(x)  # 3 classes benign, malignant, normal\n",
        "\n",
        "    # create the final model\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "    model.summary()"
      ],
      "metadata": {
        "id": "tgSDPWnF5Kdi",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:05.862921Z",
          "iopub.execute_input": "2024-02-26T20:18:05.863252Z",
          "iopub.status.idle": "2024-02-26T20:18:06.395858Z",
          "shell.execute_reply.started": "2024-02-26T20:18:05.863224Z",
          "shell.execute_reply": "2024-02-26T20:18:06.394947Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "eBsRlTLH5KgI",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:06.397122Z",
          "iopub.execute_input": "2024-02-26T20:18:06.397413Z",
          "iopub.status.idle": "2024-02-26T20:18:09.346616Z",
          "shell.execute_reply.started": "2024-02-26T20:18:06.39739Z",
          "shell.execute_reply": "2024-02-26T20:18:09.345021Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', Precision(), Recall(), AUC()])"
      ],
      "metadata": {
        "id": "Xxd7p1sB5Kid",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:09.348406Z",
          "iopub.execute_input": "2024-02-26T20:18:09.348753Z",
          "iopub.status.idle": "2024-02-26T20:18:09.397679Z",
          "shell.execute_reply.started": "2024-02-26T20:18:09.348725Z",
          "shell.execute_reply": "2024-02-26T20:18:09.39652Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # class weights for the current training fold/ balancing training set\n",
        "    train_classes = np.concatenate([train_generator_clean.classes, train_generator_noise.classes])\n",
        "\n",
        "    class_weights = class_weight.compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=np.unique(train_classes),\n",
        "        y=train_classes)\n",
        "\n",
        "    class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}"
      ],
      "metadata": {
        "id": "UBp-_aCE5KlE",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:09.398884Z",
          "iopub.execute_input": "2024-02-26T20:18:09.399136Z",
          "iopub.status.idle": "2024-02-26T20:18:09.407344Z",
          "shell.execute_reply.started": "2024-02-26T20:18:09.399115Z",
          "shell.execute_reply": "2024-02-26T20:18:09.406495Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def plot_class_distribution_with_weights(train_path, class_names, class_weights_dict):\n",
        "        class_counts = {}\n",
        "        for cls in class_names:\n",
        "            path = os.path.join(train_path, cls)\n",
        "            count = len(os.listdir(path))\n",
        "            class_counts[cls] = count\n",
        "\n",
        "        # Adjust class counts based on the class weights\n",
        "        weighted_counts = {cls: count * class_weights_dict[i] for i, (cls, count) in enumerate(class_counts.items())}\n",
        "\n",
        "        # Plotting the weighted class distribution\n",
        "        sns.barplot(x=list(weighted_counts.keys()), y=list(weighted_counts.values()), color='seagreen')\n",
        "        plt.title(\"Weighted Class Distribution\")\n",
        "        plt.xlabel(\"Classes\")\n",
        "        plt.ylabel(\"Weighted number of images\")\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    plot_class_distribution_with_weights(train_path, class_names, class_weights_dict)"
      ],
      "metadata": {
        "id": "BWD_CjSkYolg",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:09.40861Z",
          "iopub.execute_input": "2024-02-26T20:18:09.408934Z",
          "iopub.status.idle": "2024-02-26T20:18:09.602568Z",
          "shell.execute_reply.started": "2024-02-26T20:18:09.408907Z",
          "shell.execute_reply": "2024-02-26T20:18:09.601674Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # define the EarlyStopping callback\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',  # monitor the validation loss\n",
        "        patience=15, #number of epochs with no improvement the learning rate will be reduced\n",
        "        verbose=1,    # number of epochs with no improvement after which training will be stopped\n",
        "        restore_best_weights=True)  # restore model weights from the epoch with the best value of the monitored quantity"
      ],
      "metadata": {
        "id": "lsbGhnBt5Kpw",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:09.603752Z",
          "iopub.execute_input": "2024-02-26T20:18:09.604041Z",
          "iopub.status.idle": "2024-02-26T20:18:09.608737Z",
          "shell.execute_reply.started": "2024-02-26T20:18:09.604018Z",
          "shell.execute_reply": "2024-02-26T20:18:09.607872Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # use a callback for learning rate scheduling //// avoiding overfitting and can be better convergence during training\n",
        "    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10,verbose=1, mode='auto',min_delta=0.0001, cooldown=0, min_lr=0)# min_lr: meaning there is no lower limit"
      ],
      "metadata": {
        "id": "HU7QKSXE5Ksn",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:09.609953Z",
          "iopub.execute_input": "2024-02-26T20:18:09.61034Z",
          "iopub.status.idle": "2024-02-26T20:18:09.618663Z",
          "shell.execute_reply.started": "2024-02-26T20:18:09.610301Z",
          "shell.execute_reply": "2024-02-26T20:18:09.617788Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    model_checkpoint_clean = ModelCheckpoint('clean_best_model.h5', save_best_only=True)  # Save the best model\n",
        "    model_checkpoint_noise = ModelCheckpoint('noise_best_model.h5', save_best_only=True)  # Save the best model"
      ],
      "metadata": {
        "id": "jcvJw_HV5K1e",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:09.61984Z",
          "iopub.execute_input": "2024-02-26T20:18:09.620212Z",
          "iopub.status.idle": "2024-02-26T20:18:09.629129Z",
          "shell.execute_reply.started": "2024-02-26T20:18:09.620187Z",
          "shell.execute_reply": "2024-02-26T20:18:09.628175Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # visualize noise impact on the model validation accuracy over epochs.\n",
        "    # visualize noise fluctuation during the training(noisy) plot and\n",
        "\n",
        "    class NoiseScheduler(tf.keras.callbacks.Callback):\n",
        "        def __init__(self, snr_range, noise_types):\n",
        "            super(NoiseScheduler, self).__init__()\n",
        "            self.snr_range = snr_range\n",
        "            self.noise_types = noise_types\n",
        "            self.snr_log = []\n",
        "            self.noise_type_log = []  # Log for noise types\n",
        "            self.validation_accuracy = []\n",
        "            self.epoch_log = []  # log for epoch numbers\n",
        "\n",
        "        def on_epoch_begin(self, epoch, logs=None):\n",
        "            # randomly select SNR and noise type for the current epoch\n",
        "            snr_db = random.choice(self.snr_range)\n",
        "            noise_type = random.choice(self.noise_types)\n",
        "            self.snr_log.append(snr_db)\n",
        "            self.noise_type_log.append(noise_type)  # Log the noise type\n",
        "\n",
        "        def on_epoch_end(self, epoch, logs=None):\n",
        "            val_acc = logs['val_accuracy'] if 'val_accuracy' in logs else None\n",
        "            self.validation_accuracy.append(val_acc)\n",
        "            self.epoch_log.append(epoch + 1)  # Log the epoch number\n",
        "            # log the SNR value and noise type\n",
        "            print(f\"Epoch {epoch+1} - SNR: {self.snr_log[-1]} dB, Noise Type: {self.noise_type_log[-1]}\")\n",
        "\n",
        "        def on_train_end(self, logs=None):\n",
        "            # plot SNR values, noise type, and validation accuracy over epochs\n",
        "            epochs = list(range(1, len(self.validation_accuracy) + 1))\n",
        "            fig, ax1 = plt.subplots()\n",
        "\n",
        "            ax1.set_xlabel('Epoch')\n",
        "            ax1.set_ylabel('SNR (dB)', color='tab:red')\n",
        "            ax1.plot(epochs, self.snr_log, color='tab:red', marker='o', label='SNR (dB)')\n",
        "            ax1.tick_params(axis='y', labelcolor='tab:red')\n",
        "\n",
        "            # Add a second y-axis for noise type, categorical\n",
        "            ax2 = ax1.twinx()\n",
        "            noise_type_values = [self.noise_types.index(nt) for nt in self.noise_type_log]  # Convert noise types to numeric values for plotting\n",
        "            ax2.set_ylabel('Noise Type', color='tab:green')\n",
        "            ax2.scatter(epochs, noise_type_values, color='tab:green', label='Noise Type')\n",
        "            ax2.tick_params(axis='y', labelcolor='tab:green')\n",
        "\n",
        "            # add a third yaxis for validation accuracy\n",
        "            ax3 = ax1.twinx()\n",
        "            ax3.spines['right'].set_position(('outward', 60))\n",
        "            ax3.set_ylabel('Validation Accuracy', color='tab:blue')\n",
        "            ax3.plot(epochs, self.validation_accuracy, color='tab:blue', marker='x', label='Validation Accuracy')\n",
        "            ax3.tick_params(axis='y', labelcolor='tab:blue')\n",
        "\n",
        "            fig.tight_layout()\n",
        "            plt.title('SNR, Noise Type, and Validation Accuracy over Epochs')\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OVeqWNVOGH3J",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:09.630501Z",
          "iopub.execute_input": "2024-02-26T20:18:09.630877Z",
          "iopub.status.idle": "2024-02-26T20:18:09.647126Z",
          "shell.execute_reply.started": "2024-02-26T20:18:09.630847Z",
          "shell.execute_reply": "2024-02-26T20:18:09.64616Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # train the model on the training dataset and validate on the validation dataset\n",
        "    history_clean = model.fit(\n",
        "        train_generator_clean,\n",
        "        epochs=100,\n",
        "        validation_data=val_generator_clean,\n",
        "        callbacks=[early_stopping,lr_scheduler, model_checkpoint_clean],\n",
        "        class_weight=class_weights_dict\n",
        "\n",
        "        )"
      ],
      "metadata": {
        "id": "2d9HKfVE5K4F",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:18:09.648244Z",
          "iopub.execute_input": "2024-02-26T20:18:09.648544Z",
          "iopub.status.idle": "2024-02-26T20:41:56.255542Z",
          "shell.execute_reply.started": "2024-02-26T20:18:09.64852Z",
          "shell.execute_reply": "2024-02-26T20:41:56.254668Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    #plotting training and validation accuracies for clean\n",
        "    plt.plot(history_clean.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history_clean.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "E3Qi6XYk6r3F",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:41:56.256678Z",
          "iopub.execute_input": "2024-02-26T20:41:56.25694Z",
          "iopub.status.idle": "2024-02-26T20:41:56.466566Z",
          "shell.execute_reply.started": "2024-02-26T20:41:56.256919Z",
          "shell.execute_reply": "2024-02-26T20:41:56.465512Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # define SNR range and noise types for the NoiseScheduler\n",
        "    snr_range = np.linspace(30, 40, num=5)\n",
        "    noise_types = ['gaussian', 'salt_pepper']\n",
        "\n",
        "    # noiseScheduler with the SNR range and noise types\n",
        "    noise_scheduler = NoiseScheduler(snr_range, noise_types)\n",
        "\n",
        "    # fit the model\n",
        "    history_noisy = model.fit(\n",
        "        train_generator_noise,\n",
        "        epochs=100,\n",
        "        validation_data=val_generator_noise,\n",
        "        callbacks=[noise_scheduler, early_stopping, lr_scheduler, model_checkpoint_noise],\n",
        "        class_weight=class_weights_dict\n",
        "    )\n"
      ],
      "metadata": {
        "id": "G-_zidwi6r5s",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:41:56.467747Z",
          "iopub.execute_input": "2024-02-26T20:41:56.468034Z",
          "iopub.status.idle": "2024-02-26T20:54:02.95951Z",
          "shell.execute_reply.started": "2024-02-26T20:41:56.46801Z",
          "shell.execute_reply": "2024-02-26T20:54:02.958417Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # plotting training and validation accuracies for noise\n",
        "    plt.plot(history_noisy.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history_noisy.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Hs3weQJA6r9D",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:54:02.961607Z",
          "iopub.execute_input": "2024-02-26T20:54:02.961906Z",
          "iopub.status.idle": "2024-02-26T20:54:03.193991Z",
          "shell.execute_reply.started": "2024-02-26T20:54:02.961883Z",
          "shell.execute_reply": "2024-02-26T20:54:03.193153Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    results_df = pd.DataFrame({\n",
        "        'Epoch': noise_scheduler.epoch_log,\n",
        "        'SNR': noise_scheduler.snr_log,\n",
        "        'Noise_Type': noise_scheduler.noise_type_log,\n",
        "        'Validation_Accuracy': noise_scheduler.validation_accuracy\n",
        "    })\n",
        "\n",
        "    # Display the DataFrame\n",
        "    print(results_df)"
      ],
      "metadata": {
        "id": "fG-SwHe8MEMg",
        "execution": {
          "iopub.status.busy": "2024-02-26T20:54:03.195163Z",
          "iopub.execute_input": "2024-02-26T20:54:03.19547Z",
          "iopub.status.idle": "2024-02-26T20:54:03.208667Z",
          "shell.execute_reply.started": "2024-02-26T20:54:03.195428Z",
          "shell.execute_reply": "2024-02-26T20:54:03.20775Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create test data generators\n",
        "\n",
        "def create_test_generators(batch_size=32):\n",
        "\n",
        "    clean_test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)\n",
        "\n",
        "    noise_test_datagen = ImageDataGenerator(preprocessing_function=custom_preprocessing_function)\n",
        "\n",
        "    clean_test_generator = clean_test_datagen.flow_from_directory(\n",
        "        test_path,  # Path to clean test data\n",
        "        target_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False  # for evaluation\n",
        "    )\n",
        "\n",
        "    noise_test_generator = noise_test_datagen.flow_from_directory(\n",
        "        test_path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # rretrieve and display images from the noisy data generator\n",
        "    print(\"clean_test_generator:\")\n",
        "    images, labels = next(clean_test_generator)\n",
        "    plotImages(images[:5])\n",
        "\n",
        "    print(\"Noise_test_generator:\")\n",
        "    # retrieve and display images from the clean data generator\n",
        "    images, labels = next(noise_test_generator)\n",
        "    plotImages(images[:5])\n",
        "\n",
        "    return clean_test_generator, noise_test_generator"
      ],
      "metadata": {
        "id": "o3C3hkGP6sQb",
        "execution": {
          "iopub.status.busy": "2024-02-26T21:08:10.792483Z",
          "iopub.execute_input": "2024-02-26T21:08:10.793332Z",
          "iopub.status.idle": "2024-02-26T21:08:10.801181Z",
          "shell.execute_reply.started": "2024-02-26T21:08:10.793297Z",
          "shell.execute_reply": "2024-02-26T21:08:10.800117Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['benign', 'malignant', 'normal']\n",
        "\n",
        "def evaluate_model(model, generator, steps, class_names):\n",
        "    # reset the generator to ensure its at the beginning\n",
        "    generator.reset()\n",
        "    #predict on the entire dataset\n",
        "    predictions = model.predict(generator, steps=steps)\n",
        "    # get the highest probability class as the predicted class\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    #true classes from the generator\n",
        "    true_classes = generator.classes\n",
        "    #print the classification report\n",
        "    print(classification_report(true_classes, predicted_classes, target_names=class_names))\n",
        "    # Calculate and print accuracy\n",
        "    accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "    print(f'Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-26T21:09:26.4568Z",
          "iopub.execute_input": "2024-02-26T21:09:26.457522Z",
          "iopub.status.idle": "2024-02-26T21:09:26.463568Z",
          "shell.execute_reply.started": "2024-02-26T21:09:26.457489Z",
          "shell.execute_reply": "2024-02-26T21:09:26.462603Z"
        },
        "trusted": true,
        "id": "nYw7jqpgtlqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.load_weights('clean_best_model.h5')  # Load the best model saved by ModelCheckpoint"
      ],
      "metadata": {
        "id": "mZl9dXmp-TqI",
        "execution": {
          "iopub.status.busy": "2024-02-26T21:09:30.305186Z",
          "iopub.execute_input": "2024-02-26T21:09:30.305582Z",
          "iopub.status.idle": "2024-02-26T21:09:30.637355Z",
          "shell.execute_reply.started": "2024-02-26T21:09:30.305551Z",
          "shell.execute_reply": "2024-02-26T21:09:30.63658Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# Reset the global noise log before evaluation\n",
        "global_noise_log = []\n",
        "\n",
        "clean_test_gen, noise_test_gen = create_test_generators(batch_size=32)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d7HBngC3nqjz",
        "execution": {
          "iopub.status.busy": "2024-02-26T21:09:31.786961Z",
          "iopub.execute_input": "2024-02-26T21:09:31.787618Z",
          "iopub.status.idle": "2024-02-26T21:09:33.820556Z",
          "shell.execute_reply.started": "2024-02-26T21:09:31.787585Z",
          "shell.execute_reply": "2024-02-26T21:09:33.819535Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on clean test data\n",
        "\n",
        "clean_test_loss, clean_test_accuracy, clean_test_precision, clean_test_recall, clean_test_auc = model.evaluate(clean_test_gen, verbose=1)\n",
        "print(f\"Clean Test Accuracy: {clean_test_accuracy * 100:.2f}%%, Precision: {clean_test_precision}, Recall: {clean_test_recall}, AUC: {clean_test_auc}\")"
      ],
      "metadata": {
        "id": "_CJvSDAHAC-h",
        "execution": {
          "iopub.status.busy": "2024-02-26T21:09:36.543597Z",
          "iopub.execute_input": "2024-02-26T21:09:36.543982Z",
          "iopub.status.idle": "2024-02-26T21:09:38.306515Z",
          "shell.execute_reply.started": "2024-02-26T21:09:36.543952Z",
          "shell.execute_reply": "2024-02-26T21:09:38.305596Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean Test Data\n",
        "print(\"Evaluation on Clean Test Data:\")\n",
        "evaluate_model(model, clean_test_gen, len(clean_test_gen), class_names)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-26T21:09:41.875858Z",
          "iopub.execute_input": "2024-02-26T21:09:41.876656Z",
          "iopub.status.idle": "2024-02-26T21:09:43.549017Z",
          "shell.execute_reply.started": "2024-02-26T21:09:41.876621Z",
          "shell.execute_reply": "2024-02-26T21:09:43.548039Z"
        },
        "trusted": true,
        "id": "4CQIyZWMtlqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.load_weights('noise_best_model.h5')  # Load the best model saved by ModelCheckpoint"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-26T21:10:53.332248Z",
          "iopub.execute_input": "2024-02-26T21:10:53.33298Z",
          "iopub.status.idle": "2024-02-26T21:10:53.65584Z",
          "shell.execute_reply.started": "2024-02-26T21:10:53.332949Z",
          "shell.execute_reply": "2024-02-26T21:10:53.655041Z"
        },
        "trusted": true,
        "id": "JuaDtmpctlqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Evaluate on noisy test data\n",
        "noise_test_loss, noise_test_accuracy, noise_test_precision, noise_test_recall, noise_test_auc = model.evaluate(noise_test_gen, verbose=1)\n",
        "print(f\"Noisy Test Accuracy: {noise_test_accuracy * 100:.2f}%, Precision: {noise_test_precision}, Recall: {noise_test_recall}, AUC: {noise_test_auc}\")\n",
        "\n",
        "# Create a DataFrame to store metrics with noise details\n",
        "metrics_df = pd.DataFrame(global_noise_log)\n",
        "metrics_df['Accuracy'] = noise_test_accuracy\n",
        "metrics_df['Precision'] = noise_test_precision\n",
        "metrics_df['Recall'] = noise_test_recall\n",
        "metrics_df['AUC'] = noise_test_auc\n",
        "\n",
        "# Display the DataFrame\n",
        "print(metrics_df)"
      ],
      "metadata": {
        "id": "7h0sekYEoGE8",
        "execution": {
          "iopub.status.busy": "2024-02-26T21:10:56.528164Z",
          "iopub.execute_input": "2024-02-26T21:10:56.528536Z",
          "iopub.status.idle": "2024-02-26T21:10:59.178338Z",
          "shell.execute_reply.started": "2024-02-26T21:10:56.528508Z",
          "shell.execute_reply": "2024-02-26T21:10:59.177393Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For noise Test Data\n",
        "print(\"Evaluation on Noise Test Data:\")\n",
        "evaluate_model(model, noise_test_gen, len(noise_test_gen), class_names)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-26T21:11:03.871961Z",
          "iopub.execute_input": "2024-02-26T21:11:03.872768Z",
          "iopub.status.idle": "2024-02-26T21:11:06.496688Z",
          "shell.execute_reply.started": "2024-02-26T21:11:03.872734Z",
          "shell.execute_reply": "2024-02-26T21:11:06.495748Z"
        },
        "trusted": true,
        "id": "MbQsC6pltlqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Precision: measures the ratio of correctly predicted positive observations to the total predicted positives.\n",
        "\n",
        " Recal: actual positive cases were correctly identified by the model.\n",
        "\n",
        " AUC: good ability of the model to distinguish between classes."
      ],
      "metadata": {
        "id": "SGn9lDfkc0G6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gcIGqtSk-TzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dX0iIjFl6sR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Agcq1gb86sTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wSbiXTNX6sUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Sq-VIo16sZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "\n",
        "\n",
        "https://medium.com/@dnyaneshwalwadkar/fix-training-accuracy-fluctuation-over-fitting-problem-in-deep-learning-algorithm-859573090809\n",
        "\n",
        "\\\n",
        "\n",
        "https://github.com/MedMachine00/Deep-learning-based-coronary-artery-segmentation/tree/main\n",
        "\n",
        "\\\n",
        "\n",
        "https://github.com/Paperspace/DataAugmentationForObjectDetection/blob/master/quick-start.ipynb\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "\n",
        "https://www.researchgate.net/publication/352806683_Image_De-Noising_with_Machine_Learning_A_Review#:~:text=This%20paper%20explores%20the%20numerous,networks%20and%20generative%20adversarial%20networks\n",
        "\n",
        "\\\n",
        "https://arxiv.org/pdf/1609.03683.pdf\n",
        "\n",
        "\\\n",
        "\n",
        "https://keras.io/api/\n",
        "\n",
        "\\\n",
        "\n",
        "https://www.researchgate.net/publication/371699794_Deep_learning_techniques_on_3D-MRI_lung_images_for_detection_and_segmentation_of_COVID-19_virus\n",
        "\n",
        "\\\n",
        "https://link.springer.com/article/10.1007/s10462-023-10453-z#Sec21\n",
        "\n",
        "\\\n",
        "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7085309/\n",
        "\n",
        "\n",
        "\\\n",
        "https://mrimaster.com/snr/\n",
        "\n",
        "\\\n",
        "\n",
        "https://radiopaedia.org/articles/signal-to-noise-ratio-mri?lang=gb\n",
        "\n",
        "\\\n",
        "https://gist.github.com/Prasad9/28f6a2df8e8d463c6ddd040f4f6a028a?ref=blog.roboflow.com\n",
        "\n",
        "\\\n",
        "Litjens, Geert, et al. \"A survey on deep learning in medical image analysis.\" Medical image analysis 42 (2017)\n",
        "\n",
        "\n",
        "Ker, Justin, et al. \"Deep learning applications in medical image analysis.\" IEEE Access 6 (2018).\n",
        "\n",
        "https://debuggercafe.com/adding-noise-to-image-data-for-deep-learning-data-augmentation/"
      ],
      "metadata": {
        "id": "4dWdZ7CRftG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "signal-to-noise ratio (SNR) in dB. SNR is calculated using the formula:\n",
        "\n",
        "SNR (dB)\n",
        "=\n",
        "10\n",
        "×\n",
        "log\n",
        "⁡\n",
        "10\n",
        "(\n",
        "signal power/\n",
        "noise power\n",
        ")\n",
        "\n",
        "power of the signal (image pixel values)\n",
        "\n",
        "noise power(variance of the noise)"
      ],
      "metadata": {
        "id": "MOlyKlzAEdON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4bL1xPz4aLay"
      }
    }
  ]
}